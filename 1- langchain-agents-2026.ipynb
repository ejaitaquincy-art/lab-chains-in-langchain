{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1571b632",
   "metadata": {},
   "source": [
    "# LangChain Agents with LangGraph\n",
    "\n",
    "Agents are like \"tools\" for LLMs. They allow a LLM to access Google search, perform complex calculations with Python, and even make SQL queries.\n",
    "\n",
    "In this notebook we'll explore agents and how to use them in LangChain 1.x with LangGraph.\n",
    "\n",
    "We'll start by installing the prerequisite libraries that we'll be using in this example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "uZR3iGJJtdDE",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -qU langchain langchain-openai langchain_community langchain_experimental google-search-results wikipedia sqlalchemy langgraph python-dotenv numexpr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wPdWz1IdxyBR",
   "metadata": {},
   "source": [
    "## Environment Setup\n",
    "\n",
    "To run this notebook, we will need to use an OpenAI LLM. Load API keys from `.env` file using `find_dotenv()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c02c4fa2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-18T11:21:24.954734Z",
     "start_time": "2026-02-18T11:21:24.947658Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "load_dotenv(\".env\")\n",
    "\n",
    "_ = load_dotenv(find_dotenv())\n",
    "\n",
    "OPENAI_API_KEY = os.getenv('OPENAI_API_KEY')\n",
    "HUGGINGFACEHUB_API_TOKEN = os.getenv('HUGGINGFACEHUB_API_TOKEN')\n",
    "PINECONE_API_KEY = os.getenv('PINECONE_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "236d076f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "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\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.getenv(\"OPENAI_API_KEY\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6c63082a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-18T11:21:32.183006Z",
     "start_time": "2026-02-18T11:21:31.093919Z"
    }
   },
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAI\n",
    "\n",
    "# Uses OPENAI_API_KEY from environment automatically\n",
    "llm = OpenAI(temperature=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "309g_2pqxzzB",
   "metadata": {},
   "source": [
    "As we did before, we will be counting our tokens in each call."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "DsC3szr6yP3L",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-18T11:21:32.931512Z",
     "start_time": "2026-02-18T11:21:32.919282Z"
    }
   },
   "outputs": [],
   "source": [
    "from langchain_community.callbacks import get_openai_callback\n",
    "\n",
    "def count_tokens(agent, query, config=None):\n",
    "    with get_openai_callback() as cb:\n",
    "        if config:\n",
    "            result = agent.invoke(query, config)\n",
    "        else:\n",
    "            result = agent.invoke(query)\n",
    "        print(f'Spent a total of {cb.total_tokens} tokens')\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd60a97c",
   "metadata": {},
   "source": [
    "With all of that set up, let's jump into **Agents**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "101eac3d-e3a8-42ce-a5c9-9fe6d025446c",
   "metadata": {},
   "source": [
    "Large Language Models (LLMs) are incredibly powerful, yet they lack particular abilities that the \"dumbest\" computer programs can handle with ease. Logic, calculation, and search are examples of where computers typically excel, but LLMs struggle.\n",
    "\n",
    "With significant weaknesses in today's generation of LLMs, we must find solutions to these problems. One \"suite\" of potential solutions comes in the form of \"agents\".\n",
    "\n",
    "These agents don't just solve the problems we saw above but many others. In fact, adding agents has an almost unlimited upside in their LLM-enhancing abilities."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e1f31b4",
   "metadata": {},
   "source": [
    "## What is an agent?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b919c3a",
   "metadata": {},
   "source": [
    "**Definition**: The key behind agents is giving LLM's the possibility of using tools in their workflow. This is where langchain departs from the popular chatgpt implementation and we can start to get a glimpse of what it offers us as builders.\n",
    "\n",
    "The official definition of agents is the following:\n",
    "\n",
    "> Agents use an LLM to determine which actions to take and in what order. An action can either be using a tool and observing its output, or returning to the user.\n",
    "\n",
    "We can think of agents as enabling \"tools\" for LLMs. Like how a human would use a calculator for maths or perform a Google search for information — agents allow an LLM to do the same thing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a93dc920",
   "metadata": {},
   "source": [
    "## Create database\n",
    "\n",
    "We will use the agents to interact with a small sample database of stocks. We will not dive into the details because this is just a dummy tool we will build for illustrative purposes. Let's create it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "61b1f17c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-18T11:21:54.143849Z",
     "start_time": "2026-02-18T11:21:53.894792Z"
    }
   },
   "outputs": [],
   "source": [
    "from sqlalchemy import MetaData\n",
    "\n",
    "metadata_obj = MetaData()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3cc1d80e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-18T11:21:54.193254Z",
     "start_time": "2026-02-18T11:21:54.189839Z"
    }
   },
   "outputs": [],
   "source": [
    "from sqlalchemy import Column, Integer, String, Table, Date, Float\n",
    "\n",
    "stocks = Table(\n",
    "    \"stocks\",\n",
    "    metadata_obj,\n",
    "    Column(\"obs_id\", Integer, primary_key=True),\n",
    "    Column(\"stock_ticker\", String(4), nullable=False),\n",
    "    Column(\"price\", Float, nullable=False),\n",
    "    Column(\"date\", Date, nullable=False),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c9a9571a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-18T11:21:54.571387Z",
     "start_time": "2026-02-18T11:21:54.554418Z"
    }
   },
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine\n",
    "\n",
    "engine = create_engine(\"sqlite:///:memory:\")\n",
    "metadata_obj.create_all(engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "81c3081f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-18T11:21:55.034567Z",
     "start_time": "2026-02-18T11:21:55.031265Z"
    }
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "observations = [\n",
    "    [1, 'ABC', 200, datetime(2023, 1, 1)],\n",
    "    [2, 'ABC', 208, datetime(2023, 1, 2)],\n",
    "    [3, 'ABC', 232, datetime(2023, 1, 3)],\n",
    "    [4, 'ABC', 225, datetime(2023, 1, 4)],\n",
    "    [5, 'ABC', 226, datetime(2023, 1, 5)],\n",
    "    [6, 'XYZ', 810, datetime(2023, 1, 1)],\n",
    "    [7, 'XYZ', 803, datetime(2023, 1, 2)],\n",
    "    [8, 'XYZ', 798, datetime(2023, 1, 3)],\n",
    "    [9, 'XYZ', 795, datetime(2023, 1, 4)],\n",
    "    [10, 'XYZ', 791, datetime(2023, 1, 5)],\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "85fd20fa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-18T11:21:56.609571Z",
     "start_time": "2026-02-18T11:21:56.605480Z"
    }
   },
   "outputs": [],
   "source": [
    "from sqlalchemy import insert\n",
    "\n",
    "def insert_obs(obs):\n",
    "    stmt = insert(stocks).values(\n",
    "        obs_id=obs[0],\n",
    "        stock_ticker=obs[1],\n",
    "        price=obs[2],\n",
    "        date=obs[3]\n",
    "    )\n",
    "\n",
    "    with engine.begin() as conn:\n",
    "        conn.execute(stmt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6766f1f7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-18T11:21:56.797554Z",
     "start_time": "2026-02-18T11:21:56.789655Z"
    }
   },
   "outputs": [],
   "source": [
    "for obs in observations:\n",
    "    insert_obs(obs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9721648e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-18T11:21:57.154111Z",
     "start_time": "2026-02-18T11:21:57.145035Z"
    }
   },
   "outputs": [],
   "source": [
    "from langchain_community.utilities import SQLDatabase\n",
    "\n",
    "db = SQLDatabase(engine)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6325f758",
   "metadata": {},
   "source": [
    "## Agent types\n",
    "\n",
    "In this section we will review several agents and see how they 'think' and what they can do.\n",
    "\n",
    "Using agents involves three variables:\n",
    "* defining the tools or the toolkit\n",
    "* defining the llm\n",
    "* defining the agent type (now handled by LangGraph)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eaf306a",
   "metadata": {},
   "source": [
    "### Agent type #1: SQL Agent (Zero Shot React)\n",
    "\n",
    "In this first example we will use a SQL Agent which can be instantiated with `create_sql_agent`. This method uses a *toolkit* instead of a simple list of `tools`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5Z4EmMmqiOvZ",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-18T11:22:01.622212Z",
     "start_time": "2026-02-18T11:22:00.728459Z"
    }
   },
   "outputs": [],
   "source": [
    "from langchain_community.agent_toolkits import create_sql_agent, SQLDatabaseToolkit\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# Use ChatOpenAI for better performance\n",
    "chat_llm = ChatOpenAI(\n",
    "    temperature=0,\n",
    "    model=\"gpt-3.5-turbo\"\n",
    ")\n",
    "\n",
    "agent_executor = create_sql_agent(\n",
    "    llm=chat_llm,\n",
    "    toolkit=SQLDatabaseToolkit(db=db, llm=chat_llm),\n",
    "    verbose=True,\n",
    "max_iterations=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "iBqz6aFzj-2d",
   "metadata": {},
   "source": [
    "Let's see our newly created agent in action! We will ask it a question that involves a math operation over the stock prices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "MdvgpwHRic3W",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-18T11:22:11.690403Z",
     "start_time": "2026-02-18T11:22:02.204582Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new SQL Agent Executor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mAction: sql_db_list_tables\n",
      "Action Input: \u001b[0m\u001b[38;5;200m\u001b[1;3mstocks\u001b[0m\u001b[32;1m\u001b[1;3mI should query the schema of the 'stocks' table to see what columns are available.\n",
      "Action: sql_db_schema\n",
      "Action Input: stocks\u001b[0m\u001b[33;1m\u001b[1;3m\n",
      "CREATE TABLE stocks (\n",
      "\tobs_id INTEGER NOT NULL, \n",
      "\tstock_ticker VARCHAR(4) NOT NULL, \n",
      "\tprice FLOAT NOT NULL, \n",
      "\tdate DATE NOT NULL, \n",
      "\tPRIMARY KEY (obs_id)\n",
      ")\n",
      "\n",
      "/*\n",
      "3 rows from stocks table:\n",
      "obs_id\tstock_ticker\tprice\tdate\n",
      "1\tABC\t200.0\t2023-01-01\n",
      "2\tABC\t208.0\t2023-01-02\n",
      "3\tABC\t232.0\t2023-01-03\n",
      "*/\u001b[0m\u001b[32;1m\u001b[1;3mI can now construct a query to calculate the multiplication of the ratios between stock prices for 'ABC' and 'XYZ' on January 3rd and January 4th.\n",
      "Action: sql_db_query\n",
      "Action Input: SELECT (SELECT price FROM stocks WHERE stock_ticker = 'ABC' AND date = '2023-01-03') / (SELECT price FROM stocks WHERE stock_ticker = 'XYZ' AND date = '2023-01-03') * (SELECT price FROM stocks WHERE stock_ticker = 'ABC' AND date = '2023-01-04') / (SELECT price FROM stocks WHERE stock_ticker = 'XYZ' AND date = '2023-01-04');\u001b[0m\u001b[36;1m\u001b[1;3m[(0.08228117463469994,)]\u001b[0m\u001b[32;1m\u001b[1;3mThe multiplication of the ratio between stock prices for 'ABC' and 'XYZ' in January 3rd and the ratio between the same stock prices in January the 4th is approximately 0.0823.\n",
      "Final Answer: 0.0823\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Spent a total of 3112 tokens\n"
     ]
    }
   ],
   "source": [
    "result = count_tokens(\n",
    "    agent_executor,\n",
    "    \"What is the multiplication of the ratio between stock \"\n",
    "    \"prices for 'ABC' and 'XYZ' in January 3rd and the ratio \"\n",
    "    \"between the same stock prices in January the 4th?\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b2b47ed",
   "metadata": {},
   "source": [
    "### How are agents different than chains?\n",
    "\n",
    "If we look at the agent's logic and the prompt we will see some clear differences. First, we have the tools which are included in the prompt. Second we have a thought process which involves a 'thought', 'action', 'action input', 'observation' sequence.\n",
    "\n",
    "**The LLM now has the ability to 'reason' on how to best use tools** to solve our query and can combine them in intelligent ways with just a brief description of each of them. This is the ReAct paradigm - see [this paper](https://arxiv.org/pdf/2205.00445.pdf) for more details."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04d70642",
   "metadata": {},
   "source": [
    "### Agent type #2: Conversational React with LangGraph\n",
    "\n",
    "The zero shot agent has no memory. What if we want an assistant that remembers things we have talked about and can also reason about them and use tools? For that we use LangGraph with a memory checkpointer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4b6faff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.tools import tool\n",
    "import numexpr\n",
    "\n",
    "@tool\n",
    "def calculator(expression: str) -> str:\n",
    "    \"\"\"Useful for when you need to answer questions about math. Input should be a mathematical expression.\"\"\"\n",
    "    try:\n",
    "        result = numexpr.evaluate(expression).item()\n",
    "        return str(result)\n",
    "    except Exception as e:\n",
    "        return f\"Error evaluating expression: {e}\"\n",
    "\n",
    "tools = [calculator]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0aff4edf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "\n",
    "# LangGraph handles memory via checkpointers\n",
    "memory = MemorySaver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6579cef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import create_agent\n",
    "\n",
    "# Use ChatOpenAI for conversational agent\n",
    "conversational_llm = ChatOpenAI(\n",
    "    temperature=0,\n",
    "    model=\"gpt-3.5-turbo\"\n",
    ")\n",
    "\n",
    "# Create the conversational agent using LangGraph\n",
    "conversational_agent = create_agent(\n",
    "    conversational_llm, \n",
    "    tools, \n",
    "    checkpointer=memory\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cabbea50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spent a total of 547 tokens\n",
      "The result of an investment of $10,000 growing at 8% annually for 5 years with compound interest is approximately $14,693.28.\n"
     ]
    }
   ],
   "source": [
    "# Configure thread for conversation memory\n",
    "config = {\"configurable\": {\"thread_id\": \"investment-calc\"}}\n",
    "\n",
    "result = count_tokens(\n",
    "    conversational_agent,\n",
    "    {\"messages\": [(\"user\", \"What's the result of an investment of $10,000 growing at 8% annually for 5 years with compound interest?\")]},\n",
    "    config\n",
    ")\n",
    "print(result[\"messages\"][-1].content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32ee8041",
   "metadata": {},
   "source": [
    "Let's see what happens if we try to answer the question that is related to the previous one:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5e109878",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spent a total of 724 tokens\n",
      "If you start with $15,000 and follow the same 8% annual growth for 5 years with compound interest, you would have approximately $22,039.92. \n",
      "\n",
      "Therefore, compared to the previous scenario with an initial investment of $10,000, you would have approximately $7,346.64 more in this scenario.\n"
     ]
    }
   ],
   "source": [
    "result = count_tokens(\n",
    "    conversational_agent,\n",
    "    {\"messages\": [(\"user\", \"If we start with $15,000 instead and follow the same 8% annual growth for 5 years with compound interest, how much more would we have compared to the previous scenario?\")]},\n",
    "    config\n",
    ")\n",
    "print(result[\"messages\"][-1].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9d387afc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spent a total of 441 tokens\n",
      "Invest ten thousand,\n",
      "Grows to fourteen six nine three,\n",
      "Fifteen thousand more.\n"
     ]
    }
   ],
   "source": [
    "result = count_tokens(\n",
    "    conversational_agent,\n",
    "    {\"messages\": [(\"user\", \"write me haiku to remember the difference between the numbers\")]},\n",
    "    config\n",
    ")\n",
    "print(result[\"messages\"][-1].content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44135b8d",
   "metadata": {},
   "source": [
    "### Agent type #3: Wikipedia Docstore Agent\n",
    "\n",
    "This type of agent includes the interaction with a docstore. It will have two tools: 'Search' and 'Lookup'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ecc452af",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.docstore import Wikipedia\n",
    "from langchain_core.tools import tool\n",
    "\n",
    "# Create Wikipedia docstore\n",
    "wiki = Wikipedia()\n",
    "\n",
    "@tool\n",
    "def search_wikipedia(query: str) -> str:\n",
    "    \"\"\"Search Wikipedia for information about a topic.\"\"\"\n",
    "    try:\n",
    "        return wiki.search(query)\n",
    "    except Exception as e:\n",
    "        return f\"Could not find information: {e}\"\n",
    "\n",
    "@tool  \n",
    "def lookup_wikipedia(term: str) -> str:\n",
    "    \"\"\"Look up a specific term in the current Wikipedia article.\"\"\"\n",
    "    try:\n",
    "        return wiki.lookup(term)\n",
    "    except Exception as e:\n",
    "        return f\"Could not look up term: {e}\"\n",
    "\n",
    "wiki_tools = [search_wikipedia, lookup_wikipedia]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "595938a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create docstore agent using LangGraph\n",
    "docstore_agent = create_agent(\n",
    "    conversational_llm,\n",
    "    wiki_tools\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bba6b065",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spent a total of 15635 tokens\n",
      "Donald John Trump is an American politician, media personality, and businessman who served as the 45th president of the United States from 2017 to 2021. He was born on June 14, 1946, in New York City. Trump graduated from the University of Pennsylvania with a bachelor's degree in economics in 1968. He became the president of his family's real estate business in 1971, renamed it the Trump Organization, and began acquiring and building skyscrapers, hotels, casinos, and golf courses.\n",
      "\n",
      "Throughout his career, Trump has been involved in various business ventures, including real estate, licensing the Trump name for consumer products and services, side ventures like the Trump University, and owning golf clubs. He also had a media career, hosting the reality television show \"The Apprentice\" from 2004 to 2015.\n",
      "\n",
      "During his presidency, Trump implemented various policies such as imposing a travel ban on certain countries, expanding the Mexico–United States border wall, enforcing a family separation policy at the border, rolling back environmental and business regulations, signing the Tax Cuts and Jobs Act, and appointing three Supreme Court justices. He withdrew the U.S. from agreements on climate, trade, and Iran's nuclear program and initiated a trade war with China.\n",
      "\n",
      "Trump's leadership style and political agenda, often referred to as Trumpism, have reshaped the Republican Party's identity. Many of his comments and actions have been characterized as racist or misogynistic. He has made many false or misleading statements during his campaigns and presidency, to a degree unprecedented in American politics. Researchers have described his actions as authoritarian and contributing to democratic backsliding.\n",
      "\n",
      "After his presidency, Trump faced legal issues, including civil cases for sexual abuse, defamation, and business fraud. He was found guilty of falsifying business records, making him the first U.S. president convicted of a felony. Trump won the 2024 presidential election against Vice President Kamala Harris and began his second presidency with mass layoffs of federal workers, imposing tariffs, and signing the One Big Beautiful Bill Act.\n",
      "\n",
      "Trump's second presidency has been marked by conflicts of interest, targeting political opponents, mass terminations of federal employees, and expansionist foreign policy. His administration has been criticized for its authoritarian tendencies, attacks on the media, and promotion of conspiracy theories. Trump's personal life, wealth, health, and religious affiliations have also been subjects of public interest and scrutiny.\n",
      "\n",
      "For more detailed information, you can visit the [Wikipedia page on Donald Trump](https://en.wikipedia.org/wiki/Donald_Trump).\n"
     ]
    }
   ],
   "source": [
    "result = count_tokens(\n",
    "    docstore_agent, \n",
    "    {\"messages\": [(\"user\", \"Who is Donald Trump?\")]}\n",
    ")\n",
    "print(result[\"messages\"][-1].content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a5f77ac",
   "metadata": {},
   "source": [
    "In short, it contains several examples of the `Question` > `Thought` > `Action` > `Observation` loop, that include the `Search` and `Lookup` tools.\n",
    "\n",
    "If you want to learn more about this approach [this](https://arxiv.org/pdf/2210.03629.pdf) is the paper for ReAct."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aae3b5b",
   "metadata": {},
   "source": [
    "### Agent type #4: Self Ask with Search\n",
    "\n",
    "This is the first-choice agent to use when using LLM's to extract information with a search engine. The agent will ask follow-up questions and use the search functionality to get intermediate answers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "903660b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.utilities import SerpAPIWrapper\n",
    "from langchain_core.tools import tool\n",
    "\n",
    "# Note: You'll need a valid SerpAPI key in your .env file\n",
    "SERPAPI_API_KEY = os.getenv('SERPAPI_API_KEY')  # Replace with your actual key or set in .env\n",
    "\n",
    "search = SerpAPIWrapper(serpapi_api_key=SERPAPI_API_KEY)\n",
    "\n",
    "@tool\n",
    "def intermediate_answer(query: str) -> str:\n",
    "    \"\"\"Use Google search to find intermediate answers to help solve complex questions.\"\"\"\n",
    "    return search.run(query)\n",
    "\n",
    "search_tools = [intermediate_answer]\n",
    "\n",
    "# Create the search agent using LangGraph\n",
    "self_ask_with_search = create_agent(\n",
    "    conversational_llm,\n",
    "    search_tools\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f4c26c99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content='what is price of dolar in relation to euro?', additional_kwargs={}, response_metadata={}, id='10fb3c58-6efb-4888-aa38-e952c82bc77d'),\n",
       "  AIMessage(content='', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 21, 'prompt_tokens': 62, 'total_tokens': 83, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'id': 'chatcmpl-DDRqIfFs6kvSLaphg5sW2grBL4N3J', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None}, id='lc_run--019c9940-71f8-76e3-99e1-a1fcf06b2729-0', tool_calls=[{'name': 'intermediate_answer', 'args': {'query': 'current exchange rate of USD to EUR'}, 'id': 'call_H2jew3g4Wbunc5JszFQAhbXc', 'type': 'tool_call'}], invalid_tool_calls=[], usage_metadata={'input_tokens': 62, 'output_tokens': 21, 'total_tokens': 83, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
       "  ToolMessage(content='0.85 Euro', name='intermediate_answer', id='68f68011-a3f5-4ffe-bd3a-fb5276cfdcc8', tool_call_id='call_H2jew3g4Wbunc5JszFQAhbXc'),\n",
       "  AIMessage(content='The current exchange rate of USD to EUR is 0.85 Euro.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 16, 'prompt_tokens': 96, 'total_tokens': 112, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'id': 'chatcmpl-DDRqQuVFHPlFexM0GtNQoeyTBW7cw', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--019c9940-8e62-7e03-85b5-01754885bd04-0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 96, 'output_tokens': 16, 'total_tokens': 112, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "self_ask_with_search.invoke(\n",
    "    {\"messages\": [(\"user\", \"what is price of dolar in relation to euro?\")]}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e7790ae",
   "metadata": {},
   "source": [
    "The prompt is basically a series of examples to show the LLM how to ask follow up questions to a search tool until it can get to the final answer.\n",
    "\n",
    "See [this paper](https://arxiv.org/pdf/2210.03350.pdf) for more details on the Self-Ask pattern."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cd80a08",
   "metadata": {},
   "source": [
    "### Wrapping up"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97d108e2",
   "metadata": {},
   "source": [
    "And that's all for agents! In this notebook, we've updated to use LangGraph, the modern replacement for LangChain agents.\n",
    "\n",
    "Key changes from the old approach:\n",
    "* **LangGraph's `create_react_agent`** replaces `initialize_agent` \n",
    "* **Memory** is handled via `MemorySaver` checkpointer instead of `ConversationBufferMemory`\n",
    "* **Tools** are defined using the `@tool` decorator from `langchain_core.tools`\n",
    "* **Agent invocation** uses a message-based format: `{\"messages\": [(\"user\", \"query\")]}`\n",
    "\n",
    "There are many other things you can do with LangGraph agents:\n",
    "* Create custom agent workflows with complex state management\n",
    "* Build multi-agent systems\n",
    "* Add human-in-the-loop interactions\n",
    "* Trace every call through LangSmith"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "comparison-table",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Migration Comparison Table: LangChain 0.x vs 1.0+\n",
    "\n",
    "| Old (LangChain 0.x) | New (LangChain 1.0+) | Notes |\n",
    "|---------------------|----------------------|-------|\n",
    "| `from langchain.llms import OpenAI` | `from langchain_openai import OpenAI` | Moved to dedicated `langchain_openai` package |\n",
    "| `from langchain.chat_models import ChatOpenAI` | `from langchain_openai import ChatOpenAI` | Moved to dedicated `langchain_openai` package |\n",
    "| `from langchain.agents import initialize_agent, AgentType` | `from langgraph.prebuilt import create_react_agent` | Use LangGraph for agents |\n",
    "| `from langchain.memory import ConversationBufferMemory` | `from langgraph.checkpoint.memory import MemorySaver` | Memory via checkpointers |\n",
    "| `from langchain.tools import Tool` | `from langchain_core.tools import tool` (decorator) | Use `@tool` decorator |\n",
    "| `from langchain.chains import LLMMathChain` | Use `numexpr` for math evaluation | LLMMathChain removed, use numexpr directly |\n",
    "| `Tool(name=..., func=..., description=...)` | `@tool` decorator with docstring | Cleaner tool definition |\n",
    "| `initialize_agent(tools, llm, agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION)` | `create_react_agent(llm, tools)` | LangGraph handles agent type |\n",
    "| `initialize_agent(..., memory=memory)` | `create_react_agent(..., checkpointer=memory)` | Memory as checkpointer |\n",
    "| `agent.run(query)` | `agent.invoke({\"messages\": [(\"user\", query)]}, config)` | Message-based invocation |\n",
    "| `agent.run(query)` returns string | `agent.invoke(...)` returns dict with `messages` | Access via `result[\"messages\"][-1].content` |\n",
    "| `from langchain.utilities import SQLDatabase` | `from langchain_community.utilities import SQLDatabase` | Moved to `langchain_community` |\n",
    "| `from langchain.callbacks import get_openai_callback` | `from langchain_community.callbacks import get_openai_callback` | Moved to `langchain_community` |\n",
    "| `SQLDatabaseChain` | `create_sql_agent` with `SQLDatabaseToolkit` | Chain deprecated, use agent toolkit |"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
